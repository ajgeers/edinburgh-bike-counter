{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_bike_counter_data(datapath='data',\n",
    "                          force_download=False):\n",
    "    \"\"\"Download and cache the Edinburgh bike counter dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapath : string (optional)\n",
    "        location to save the data\n",
    "    force_download : bool (optional)\n",
    "        if True, force redownload of data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas.DataFrame\n",
    "        Edinburgh bike counter data\n",
    "    \n",
    "    \"\"\"\n",
    "    html_page = urlopen('http://www.edinburghopendata.info/dataset/bike-counter-data-set-cluster')\n",
    "    soup = BeautifulSoup(html_page, 'html5lib')\n",
    "\n",
    "    dfs = []\n",
    "    for a in soup.find_all('a', attrs={'href': re.compile(\"\\.csv$\")}):\n",
    "        \n",
    "        # Download data\n",
    "        url = a.get('href')\n",
    "        filename = os.path.basename(url)\n",
    "        filepath = os.path.join(datapath, filename)\n",
    "        if force_download or not os.path.exists(filepath):\n",
    "            urlretrieve(url, filepath)\n",
    "\n",
    "        # Read data and set datetime as index\n",
    "        df = pd.read_csv(filepath,\n",
    "                         index_col='date')\n",
    "        try:\n",
    "            df.index = pd.to_datetime(df.index, format='%d/%m/%Y')\n",
    "        except TypeError:\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        df.index = df.index + pd.to_timedelta(df['time'], unit='h')\n",
    "\n",
    "        # Sum all channels to get single value for each bike counter\n",
    "        bike_counter_name = os.path.splitext(filename)[0]\n",
    "        df = pd.DataFrame(df.filter(regex='channel', axis=1).sum(axis=1),\n",
    "                          columns=[bike_counter_name])\n",
    "        dfs.append(df)\n",
    "        \n",
    "    data = pd.concat(dfs, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = get_bike_counter_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
